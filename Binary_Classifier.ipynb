{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hemnemne/master_thesis_submission/blob/main/Binary_Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions\n",
        "First, we need to set up all functions we need."
      ],
      "metadata": {
        "id": "SNI178QgzWph"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to Load the Data"
      ],
      "metadata": {
        "id": "5WGF4kTnKl7p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt5AItypKb0P"
      },
      "outputs": [],
      "source": [
        "def mount_drive():\n",
        "  \"\"\"\n",
        "  Mounts the Google Drive to be able to retrieve and store data. \n",
        "  You will be asked to give permissions as soon as you run the function. \n",
        "  \"\"\"\n",
        "  \n",
        "  from google.colab import drive\n",
        "  drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def load_data(base_path:str = \"/content/drive/MyDrive/Masterarbeit/Colab_Data/LeiKa/\"):\n",
        "  \"\"\"\n",
        "  Load both the FAQ data and the services we use for training. \n",
        "  They both need to be stored as separate .csv files. \n",
        "  All the data here is taken from the LeiKa in the Solr Drive. \n",
        "  \"\"\"\n",
        "\n",
        "  # where are the files?\n",
        "  file_path_services = base_path + \"services.csv\"\n",
        "  file_path_faqs = base_path + \"faq.csv\"\n",
        "\n",
        "  # get the dataframes\n",
        "\n",
        "  # needs to have at least two columns: sentences and their labels\n",
        "  df_services = pd.read_csv(file_path_services)\n",
        "  df_faq = pd.read_csv(file_path_faqs)\n",
        "  \n",
        "  return df_services, df_faq"
      ],
      "metadata": {
        "id": "GrUADleOgTPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzH20V6xQGz4"
      },
      "outputs": [],
      "source": [
        "def get_possibilities():\n",
        "  \"\"\"\n",
        "  Here, we define all possible parameters we can choose from. \n",
        "  This later makes the parameter choices more easily accessible.\n",
        "  All of them are stored in a dictionary like so:\n",
        "  For each parameter (keys) we define a list of possible settings (values).\n",
        "  \"\"\"\n",
        "\n",
        "  possibilities = {\n",
        "      'train_test_split': [0.9, 0.0, 0.8],\n",
        "      'german_only': [True, False],\n",
        "      'learning_rate': [5e-05, .1, .01, 5e-03, 5e-06],\n",
        "      'epochs': [8,4,10,16],\n",
        "      'decay': [0.01, 5e-05/10, 0.0], # second option is (lr / # of epochs)\n",
        "      'num_attention_heads': [12,16],\n",
        "      'num_hidden_layers': [12,24],\n",
        "      'random_state': [100, 42, 55],\n",
        "      'train_bert': [True,False],\n",
        "      'name_only': [True,False],\n",
        "      'faq_q_only': [True,False],\n",
        "      'remove_special_chars': [True,False],\n",
        "      'weighted': [None,{0:1.0 , 1:2.0}, {0:2.0 , 1:1.0}],\n",
        "      'current_model': ['german_standard_sota', 'german_cased', 'german_uncased', 'english_basic', 'german_gelectra'],\n",
        "      'shuffle_between_training': [False,True],\n",
        "      'distill': [False,True],\n",
        "      'sample_size': [2000,1000,4000],\n",
        "      'override': [True,False],\n",
        "      'explainable': [False,True],\n",
        "      'optimizer': ['Adam', 'SGD', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl'],\n",
        "      'output_attentions': [False,True],\n",
        "      'output_hidden_states': [False,True],\n",
        "      'batch_size': [8],\n",
        "      'shuffle_tf': [False,True],\n",
        "      'enrich_FAQs' : [False,True],\n",
        "      'real_data' : [False,True],\n",
        "      'cluster': [False,True]\n",
        "      }\n",
        "\n",
        "  return possibilities"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def get_parameters(possibilities:dict):\n",
        "  \"\"\"\n",
        "  Here, we get all parameters as they need to be.\n",
        "  This is where we can adjust them.\n",
        "\n",
        "  This method also initializes Models and Optimoizers globally. \n",
        "  They can then be received in the whole script as dictionaries if needed. \n",
        "\n",
        "  We also install additional requirements, \n",
        "  if the \"explainable\" parameter is set.\n",
        "  \"\"\"\n",
        "\n",
        "  parameters = {\n",
        "      'train_test_split':possibilities[\"train_test_split\"][0],\n",
        "      'german_only':possibilities[\"german_only\"][0],\n",
        "      'learning_rate':possibilities[\"learning_rate\"][0],\n",
        "      'epochs':possibilities[\"epochs\"][0],\n",
        "      'decay':possibilities[\"decay\"][0],\n",
        "      'num_attention_heads':possibilities[\"num_attention_heads\"][0],\n",
        "      'num_hidden_layers':possibilities[\"num_hidden_layers\"][0],\n",
        "      'random_state':possibilities[\"random_state\"][0],\n",
        "      'train_bert':possibilities[\"train_bert\"][0],\n",
        "      'name_only':possibilities[\"name_only\"][0],\n",
        "      'faq_q_only':possibilities[\"faq_q_only\"][0],\n",
        "      'remove_special_chars':possibilities[\"remove_special_chars\"][0],\n",
        "      'weighted':possibilities[\"weighted\"][1],\n",
        "      'current_model':possibilities[\"current_model\"][0],\n",
        "      'shuffle_between_training':possibilities[\"shuffle_between_training\"][0],\n",
        "      'distill':possibilities[\"distill\"][0],\n",
        "      'sample_size':possibilities[\"sample_size\"][0],\n",
        "      'override':possibilities[\"override\"][1],\n",
        "      'explainable':possibilities[\"explainable\"][1],\n",
        "      'optimizer':possibilities[\"optimizer\"][0],\n",
        "      'output_attentions':possibilities[\"output_attentions\"][0],\n",
        "      'output_hidden_states':possibilities[\"output_hidden_states\"][0],\n",
        "      'batch_size':possibilities[\"batch_size\"][0],\n",
        "      'shuffle_tf':possibilities[\"shuffle_tf\"][0],\n",
        "      'enrich_FAQs':possibilities[\"enrich_FAQs\"][0],\n",
        "      'real_data':possibilities[\"real_data\"][0],\n",
        "      'cluster':possibilities[\"cluster\"][0]\n",
        "      }\n",
        "\n",
        "  # if we train on real data, we want a sample size of 4000\n",
        "  if parameters[\"real_data\"]:\n",
        "    parameters['sample_size']=possibilities[\"sample_size\"][2]\n",
        "\n",
        "  # all possible models\n",
        "\n",
        "  # \"sota\" : state of the art\n",
        "  # \"cased\" : Gross/Kleinschreibung beruecksichtigen\n",
        "  # \"uncased\" : Gross/Kleinschreibung nicht beruecksichtigen\n",
        "\n",
        "  global models \n",
        "  models = {\n",
        "      \"german_standard_sota\":\"bert-base-german-cased\", \n",
        "      \"german_cased\":\"dbmdz/bert-base-german-cased\",\n",
        "      \"german_uncased\" : \"dbmdz/bert-base-german-uncased\",\n",
        "      \"english_basic\":\"bert-base-cased\",\n",
        "      \"german_gelectra\": \"deepset/gelectra-large\"}\n",
        "\n",
        "  # all possible optimizers\n",
        "\n",
        "  global optimizers\n",
        "  optimizers = {\"SGD\":tf.keras.optimizers.SGD(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]),\n",
        "                \"RMSprop\":tf.keras.optimizers.RMSprop(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]), \n",
        "                \"Adam\":tf.keras.optimizers.Adam(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]), \n",
        "                \"Adadelta\":tf.keras.optimizers.Adadelta(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]), \n",
        "                \"Adagrad\":tf.keras.optimizers.Adagrad(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]), \n",
        "                \"Adamax\":tf.keras.optimizers.Adamax(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]), \n",
        "                \"Nadam\":tf.keras.optimizers.Nadam(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"]),\n",
        "                \"Ftrl\":tf.keras.optimizers.Ftrl(learning_rate=parameters[\"learning_rate\"],decay=parameters[\"decay\"])}\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "FwDVsAPwKZq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for Text Classification"
      ],
      "metadata": {
        "id": "u491BbWoKr64"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pre Process"
      ],
      "metadata": {
        "id": "FDNSNh9MUY05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This Class takes care of the Timing of the Training\n",
        "\n",
        "import keras\n",
        "import time\n",
        "\n",
        "class TimeHistory(keras.callbacks.Callback):\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.times = []\n",
        "\n",
        "    def on_epoch_begin(self, batch, logs={}):\n",
        "        self.epoch_time_start = time.time()\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        self.times.append(time.time() - self.epoch_time_start)"
      ],
      "metadata": {
        "id": "lSwsxeRt1IXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nospecial(text:str):\n",
        "  \"\"\"\n",
        "  Removes all non-words from a string using regular expressions. \n",
        "  \"\"\"\n",
        "\n",
        "  import re\n",
        "  text = re.sub(\"[^a-zA-Z0-9äöüß]+\", \" \",text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "NZ87lKq5Ke9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the following functions, we need the transformers library\n",
        "\n",
        "%pip install transformers\n",
        "from transformers import AutoTokenizer"
      ],
      "metadata": {
        "id": "j2XOAyOmLMzP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9ba76c7-c25b-4d9d-d438-6cd96911611e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h50ORrWCF_y1"
      },
      "outputs": [],
      "source": [
        "def pre_process(df_services:pd.DataFrame, df_faq:pd.DataFrame, parameters:dict):\n",
        "  \"\"\"\n",
        "  This is the pre-processor. \n",
        "  It takes both the service and FAQ dataframe as inputs. \n",
        "  Depending on the given parameters, it will adjust the texts. \n",
        "  It returns the complete and shuffled training data as a DataFrame. \n",
        "  \"\"\"\n",
        "\n",
        "  if parameters[\"cluster\"]:\n",
        "    # get the validation set\n",
        "    df = pd.read_csv(\"/content/drive/MyDrive/Masterarbeit/Colab_Data/classifications_for_clustering.csv\")\n",
        "    # the new label now is 1 for agree and 0 for disagree\n",
        "    df[\"label\"] = df[\"same\"].to_list()\n",
        "    df = df[[\"text\",\"label\"]]\n",
        "  else:\n",
        "    # if you only want to train on the name / question and not the description, set the following\n",
        "    df = pd.DataFrame()\n",
        "    df_2 = pd.DataFrame()\n",
        "    if parameters[\"name_only\"]:\n",
        "      df[\"text\"] = df_services[\"d115Name\"]\n",
        "    else:\n",
        "      df[\"text\"] = df_services[\"d115Name\"] + \" \" + df_services[\"d115Synonym\"]\n",
        "    if parameters[\"faq_q_only\"]:\n",
        "      faqs_temp = df_faq[\"faqQuestionMain\"].to_list()\n",
        "      if parameters[\"enrich_FAQs\"]:\n",
        "        # if we want to enrich the training data, we add additional FAQs\n",
        "        new_faq_test_data = pd.read_csv(\"/content/drive/MyDrive/Masterarbeit/Colab_Data/new_faq_data_for_enriching.csv\").drop_duplicates(subset=[\"angeklickte FAQ-Frage\"]).sample(frac=1.,random_state=100)    \n",
        "        additional_faqs = new_faq_test_data[\"angeklickte FAQ-Frage\"].to_list()\n",
        "        faqs_temp.extend(additional_faqs)\n",
        "      df_2[\"text\"] = faqs_temp\n",
        "      \n",
        "    else:\n",
        "      df_2[\"text\"] = df_faq[\"faqAll\"]\n",
        "\n",
        "    df[\"label\"]=[0 for i in range(len(df_services))]\n",
        "    df_2[\"label\"]=[1 for i in range(len(df_2[\"text\"].to_list()))]\n",
        "\n",
        "    # combine the two dataframes\n",
        "    df = df.append(df_2)\n",
        "  # and then shuffle the df\n",
        "  df = df.sample(frac=1.0,random_state=parameters[\"random_state\"])\n",
        "\n",
        "  # remove special chars if needed\n",
        "  if parameters[\"remove_special_chars\"]:\n",
        "    df[\"text\"] = [nospecial(i) for i in df[\"text\"].to_list()]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now, we also need transformers datasets\n",
        "# after this, you must restart (watch concole output)\n",
        "\n",
        "%pip install transformers datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NJVKVMWNIqk",
        "outputId": "4847ddb6-78c5-4e88-d9d7-5c16e184def6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.1.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.10.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_df(df:pd.DataFrame, parameters:dict):\n",
        "  \"\"\"\n",
        "  Here, we take a full dataframe (training and testing data) as an input. \n",
        "  This DataFrame needs to have both a \"text\" and a \"label\" column. \n",
        "  It gets split (depending on the split parameter) and tokenized. \n",
        "  The transformers dataset is returned.\n",
        "  This can then be turned into tensors to be fed into the model. \n",
        "  \"\"\"\n",
        "\n",
        "  split = parameters[\"train_test_split\"]\n",
        "\n",
        "  def split_df(df:pd.DataFrame, split:float=parameters[\"train_test_split\"]):\n",
        "    \"\"\"\n",
        "    Splits a given DataFrame into training set and set, depending \n",
        "    on the split parameter. \n",
        "    \"\"\"\n",
        "    # Splits a DataFrame into Train and Test DataFrames\n",
        "    separator = int(split*df.shape[0])\n",
        "    train_df = df.iloc[:separator]\n",
        "    test_df = df.iloc[separator:]\n",
        "    return train_df,test_df\n",
        "\n",
        "  import datasets\n",
        "\n",
        "  def create_ds(train_df:pd.DataFrame, test_df:pd.DataFrame):\n",
        "    \"\"\"\n",
        "    Creates a Transformers Dataset from given test and train DataFrames. \n",
        "    This is necessary for further processing of the data. \n",
        "    \"\"\"\n",
        "\n",
        "    train_dataset = datasets.Dataset.from_dict(train_df)\n",
        "    test_dataset = datasets.Dataset.from_dict(test_df)\n",
        "\n",
        "    return datasets.DatasetDict({\"train\":train_dataset,\"test\":test_dataset})\n",
        "\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(models[parameters[\"current_model\"]], \n",
        "                              output_attentions=parameters[\"output_attentions\"])\n",
        "\n",
        "  def tokenize_function(examples):\n",
        "    \"\"\"\n",
        "    This tokenizes text. \n",
        "    The tokenize function needs to be defined up front in order for the \n",
        "    dataset.map() function to work. \n",
        "    \"\"\"\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "  # depending on the split parameter, we either use everything \n",
        "  # or seperate training and testing sets. \n",
        "\n",
        "  if split > .0:\n",
        "    train_df,test_df = split_df(df,split=split)\n",
        "    dataset = create_ds(train_df,test_df)\n",
        "  else:\n",
        "    dataset = datasets.Dataset.from_dict(df)\n",
        "    \n",
        "  return dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "eFGPExfN6Y12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we now need the DefaultDataCollator\n",
        "\n",
        "from transformers import DefaultDataCollator"
      ],
      "metadata": {
        "id": "XDrU1JYDP4nH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor_df(df:pd.DataFrame,parameters:dict, val=False):\n",
        "  \"\"\"\n",
        "  Turns our transformers.Dataset into tensors. \n",
        "  These tensors can then be fed into the model.\n",
        "\n",
        "  This method can be seen as an end-to-end processor:\n",
        "  It takes a DataFrame that has both a text and a label column. \n",
        "  It returns tensors, which can be used to fit() a model. \n",
        "\n",
        "  val:\n",
        "  If we want to \"tensorize\" our validation dataset, \n",
        "  we do not want to split it since we do not train or test, we just validate. \n",
        "  \"\"\"\n",
        "\n",
        "  split_temp = parameters[\"train_test_split\"]\n",
        "\n",
        "  if val:\n",
        "    parameters[\"train_test_split\"] = .0\n",
        "\n",
        "  batch_size = parameters[\"batch_size\"]\n",
        "  shuffle = parameters[\"shuffle_tf\"]\n",
        "\n",
        "  tokenized_datasets = tokenize_df(df,parameters=parameters)\n",
        "\n",
        "  data_collator = DefaultDataCollator(return_tensors=\"tf\")\n",
        "\n",
        "  \n",
        "  # Set the split back to where it was after tokenization\n",
        "  parameters[\"train_test_split\"] = split_temp\n",
        "\n",
        "  try:\n",
        "\n",
        "    # either saves both training and testing set ...\n",
        "\n",
        "    tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
        "        columns=[\"attention_mask\", \"input_ids\"],\n",
        "        label_cols=[\"labels\"],\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=data_collator,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    tf_test_dataset = tokenized_datasets[\"test\"].to_tf_dataset(\n",
        "        columns=[\"attention_mask\", \"input_ids\"],\n",
        "        label_cols=[\"labels\"],\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=data_collator,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    result = tf_train_dataset, tf_test_dataset\n",
        "\n",
        "  except (KeyError, ValueError):\n",
        "\n",
        "    # ... or only returns one result\n",
        "\n",
        "    result = tokenized_datasets.to_tf_dataset(\n",
        "        columns=[\"attention_mask\", \"input_ids\"],\n",
        "        label_cols=[\"labels\"],\n",
        "        shuffle=shuffle,\n",
        "        collate_fn=data_collator,\n",
        "        batch_size=batch_size,\n",
        "    ) , None\n",
        "\n",
        "  # if we want to validate, we use this for predictions.\n",
        "  # thus, we only return the first part of the tuple\n",
        "  # None the predict() method cannot handle\n",
        "  if val:\n",
        "    return result[0]\n",
        "  else:\n",
        "    return result"
      ],
      "metadata": {
        "id": "TMQWOw5q6cos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classify"
      ],
      "metadata": {
        "id": "z2xOMutJUfjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "zlQQXnEMT0yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(parameters:dict):\n",
        "  \"\"\"\n",
        "  This is how we get the actual model we want to train. \n",
        "  If we already have an available and stored model from before at hand \n",
        "  (saved in our drive) AND if the \"override\" parameter is set to True, \n",
        "  this method will automatically load that model. \n",
        "\n",
        "  A keras.model is returned that can then be trained and make predictions. \n",
        "  \"\"\"\n",
        "\n",
        "  current_model = models[parameters[\"current_model\"]]\n",
        "  override = parameters[\"override\"]\n",
        "  output_hidden_states=parameters[\"output_hidden_states\"]\n",
        "  output_attentions=parameters[\"output_attentions\"]\n",
        "  num_hidden_layers=parameters[\"num_hidden_layers\"]\n",
        "\n",
        "  if override:\n",
        "    model = TFAutoModelForSequenceClassification.from_pretrained(current_model, num_labels=2,output_attentions=output_attentions,output_hidden_states=output_hidden_states,num_hidden_layers=num_hidden_layers)\n",
        "  else:\n",
        "    try:\n",
        "      model = TFAutoModelForSequenceClassification.from_pretrained(\"./my_model/\",output_attentions=output_attentions,num_hidden_layers=num_hidden_layers)\n",
        "    except OSError:  \n",
        "      model = TFAutoModelForSequenceClassification.from_pretrained(current_model, num_labels=2,output_attentions=output_attentions,output_hidden_states=output_hidden_states,num_hidden_layers=num_hidden_layers)\n",
        "\n",
        "  if current_model != \"deepset/gelectra-large\":\n",
        "    model.attention_probs_dropout_prob= 0.1\n",
        "    model.hidden_act= \"gelu\"\n",
        "    model.hidden_dropout_prob= 0.1\n",
        "    model.hidden_size= 768\n",
        "    model.initializer_range= 0.02\n",
        "    model.intermediate_size= 3072\n",
        "    model.layer_norm_eps= 1e-12\n",
        "    model.max_position_embeddings= 512\n",
        "    model.model_type= \"bert\"\n",
        "    model.num_attention_heads= parameters[\"num_attention_heads\"]\n",
        "    model.num_hidden_layers= parameters[\"num_hidden_layers\"]\n",
        "    model.pad_token_id= 0\n",
        "    model.position_embedding_type= \"absolute\"\n",
        "    model.transformers_version= \"4.21.0\"\n",
        "    model.type_vocab_size= 2\n",
        "    model.use_cache= True\n",
        "    model.vocab_size= 30000\n",
        "\n",
        "    # this is how to get the layers:\n",
        "\n",
        "    layer = model.get_layer('bert')\n",
        "\n",
        "    # and this is how you make a layer NOT trainable\n",
        "\n",
        "    layer.trainable = parameters[\"train_bert\"]\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "YYOsXyAC6f5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipVWL6bkI7ak"
      },
      "outputs": [],
      "source": [
        "def get_test_data(parameters:dict, different_random_state=False, \n",
        "                  path=\"/content/drive/MyDrive/Masterarbeit/Colab_Data/log.csv\"):\n",
        "  \"\"\"\n",
        "  We use this for after the Training, to evaluate the model. \n",
        "  We get test data from the LOG.\n",
        "  It is split exactly 1:1 between services and FAQs. \n",
        "  Afterwards, it gets shuffled and a DataFrame with text and labels is returned.\n",
        "  \"\"\"\n",
        "\n",
        "  sample_size = parameters[\"sample_size\"]\n",
        "  german_only = parameters[\"german_only\"]\n",
        "\n",
        "  test_data = pd.read_csv(path)\n",
        "\n",
        "  if german_only:\n",
        "    test_data = test_data[test_data[\"searchResultsWithScore\"] == \"de\"]\n",
        "\n",
        "  test_data = test_data[((test_data[\"selectedID\"].str.len() == 6)  & (test_data[\"userQuestion\"] == \"SERVICE_SELECTION_REQUEST\"))| (test_data[\"userQuestion\"] == \"FAQ_ANSWER\")]\n",
        "  test_data = test_data[[\"sessionID\",\"userQuestion\"]]\n",
        "  test_data.columns = [\"text\",\"label\"]\n",
        "\n",
        "  if parameters[\"remove_special_chars\"]:\n",
        "    test_data[\"text\"] = [nospecial(i) for i in test_data[\"text\"].to_list()]\n",
        "\n",
        "  test_data[\"label\"] = test_data[\"label\"].replace({\"SERVICE_SELECTION_REQUEST\":0,\"FAQ_ANSWER\":1})\n",
        "  test_data=test_data.sample(frac=1.,random_state=parameters[\"random_state\"])\n",
        "\n",
        "  if different_random_state:\n",
        "    test_data = test_data.sample(frac=1., random_state=1234)\n",
        "\n",
        "  test_data_0 = test_data[test_data[\"label\"]==0].iloc[:int(sample_size/2)]\n",
        "  test_data_1 = test_data[test_data[\"label\"]==1].iloc[:int(sample_size/2)]\n",
        "  test_data = test_data_0.append(test_data_1)\n",
        "  test_data = test_data.sample(frac=1., random_state=parameters[\"random_state\"])\n",
        "\n",
        "  return test_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_data(parameters:dict):\n",
        "  \"\"\"\n",
        "  Depending on the parameter settings, we get the data from the LeiKa or the Log.  \n",
        "  \"\"\"\n",
        "  \n",
        "  # Do we want to train on log data / real data? ...\n",
        "  if parameters[\"real_data\"]:\n",
        "    df = get_test_data(sample_size=parameters[\"sample_size\"], \n",
        "                      german_only=parameters[\"german_only\"], \n",
        "                      different_random_state=True)\n",
        "  # ... or do we train on the LeiKa\n",
        "  else:\n",
        "    df = pre_process(df_services=df_services, df_faq=df_faq, \n",
        "                    parameters=parameters)\n",
        "    \n",
        "  return df"
      ],
      "metadata": {
        "id": "lTjBWwQky7_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model,parameters, tf_train_dataset, tf_test_dataset):\n",
        "  \"\"\"\n",
        "  Trains the model. \n",
        "  Depending on the \"shuffle_between_training\" parameter, \n",
        "  we train half-and-half or all the way.\n",
        "  We also track the time for each epoch. \n",
        "\n",
        "  At tbe end, the model is saved. \n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  time_callback = TimeHistory()\n",
        "\n",
        "\n",
        "  class_weight = parameters[\"weighted\"]\n",
        "\n",
        "  if not parameters[\"shuffle_between_training\"]:\n",
        "\n",
        "    history = model.fit(tf_train_dataset, validation_data=tf_test_dataset, epochs=parameters[\"epochs\"], class_weight=class_weight, callbacks=[time_callback])\n",
        "    hist = history.history\n",
        "    \n",
        "  else:\n",
        "\n",
        "    # if we split the epochs, we also need to split the results\n",
        "\n",
        "    epochs = int(parameters[\"epochs\"]/2)\n",
        "    history_1 = model.fit(tf_train_dataset, validation_data=tf_test_dataset, epochs=epochs, class_weight=class_weight, callbacks=[time_callback])\n",
        "    df = df.sample(frac=1.0,random_state=parameters[\"random_state\"])\n",
        "\n",
        "    tf_train_dataset, tf_test_dataset = tensor_df(df, parameters=parameters)\n",
        "    \n",
        "    history_2 = model.fit(tf_train_dataset, validation_data=tf_test_dataset, epochs=epochs, class_weight=class_weight, callbacks=[time_callback])\n",
        "    hist = history_1.history\n",
        "    hist_2 = history_2.history\n",
        "    for key in hist.keys():\n",
        "      hist[key] = hist[key].extend(hist_2[key])\n",
        "\n",
        "\n",
        "  model.save_pretrained(\"my_model\")\n",
        "\n",
        "  return model, hist, time_callback"
      ],
      "metadata": {
        "id": "p7cHZGPO2rwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate"
      ],
      "metadata": {
        "id": "45CYA-x4Sc6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for the evaluation of the model, we certainly need numpy\n",
        "\n",
        "import numpy"
      ],
      "metadata": {
        "id": "8Eb8cmP3SmuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def invert_labels(y_true:list, y_pred:list):\n",
        "  \"\"\"\n",
        "  Just a helper method that inverts the labels for further evaluation.\n",
        "  The goal is to take both the services and the FAQ perspective. \n",
        "  \"\"\"\n",
        "\n",
        "  translator = {0:1, 1:0}\n",
        "  y_true = [translator[i] for i in y_true]\n",
        "  y_pred = [translator[i] for i in y_pred]\n",
        "  \n",
        "  return y_true,y_pred"
      ],
      "metadata": {
        "id": "87jeOJfiShrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def score(cm, true_label:str, y_true, y_pred):\n",
        "  \"\"\"\n",
        "  We compute all relevant scores for the evaluation here. \n",
        "  The method takes a confusion matrix and the true labels as an input and \n",
        "  returns a score series with all relevant values. \n",
        "  \"\"\"\n",
        "\n",
        "  tn, fp, fn, tp = cm.ravel()\n",
        "  scores = {}\n",
        "\n",
        "  scores[f\"{true_label}_tn\"] = tn\n",
        "  scores[f\"{true_label}_fp\"] = fp\n",
        "  scores[f\"{true_label}_fn\"] = fn\n",
        "  scores[f\"{true_label}_tp\"] = tp\n",
        "  scores[f\"{true_label}_false_positive_rate\"] = fp / (fp + tn)\n",
        "  scores[f\"{true_label}_false_negative_rate\"] = fn / (tp + fn)\n",
        "  scores[f\"{true_label}_true_negative_rate\"] = tn / (tn + fp)\n",
        "  scores[f\"{true_label}_negative_predictive_value\"] = tn/ (tn + fn)\n",
        "  scores[f\"{true_label}_false_discovery_rate\"] = fp/ (tp + fp)\n",
        "  scores[f\"{true_label}_recall\"] = tp / (tp + fn)\n",
        "  scores[f\"{true_label}_precision\"] = tp/ (tp + fp)\n",
        "  scores[f\"{true_label}_accuracy\"] = (tp + tn) / (tp + fp + fn + tn)\n",
        "  scores[f\"{true_label}_f1\"] = f1_score(y_true, y_pred)\n",
        "  scores[f\"{true_label}_matthews_corr\"] = matthews_corrcoef(y_true, y_pred)\n",
        "\n",
        "  return pd.Series(scores)"
      ],
      "metadata": {
        "id": "RZaWu2h0Stpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(predictions, sample_val):\n",
        "  \"\"\"\n",
        "  The Input here are all \n",
        "  predictions the model made and the \n",
        "  sample_val validation data with the true labels. \n",
        "\n",
        "  It attaches the text legth and predictions to the validation dataset. \n",
        "  Thus, we return a DataFrame with \n",
        "  the original text, predicted labels, true labels and text length. \n",
        "  \"\"\"\n",
        "\n",
        "  sample_val[\"pred_label\"] = [numpy.argmax(i) for i in predictions['logits']]\n",
        "  sample_val[\"text_length\"] = [len(i) for i in sample_val[\"text\"].to_list()]\n",
        "  check = sample_val[\"label\"] == sample_val[\"pred_label\"]\n",
        "  sample_val[\"same\"] = [int(i) for i in check]  \n",
        "  \n",
        "  return sample_val"
      ],
      "metadata": {
        "id": "omxJVfnwSv_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_y(sample_val):\n",
        "  \"\"\"\n",
        "  Here, from the validation data, we get y_true and y_pred \n",
        "  --> return the true and the predicted labels as list(s)\n",
        "  \"\"\"\n",
        "\n",
        "  y_true = sample_val[\"label\"].to_list()\n",
        "  y_pred = sample_val[\"pred_label\"].to_list()\n",
        "  \n",
        "  return y_true, y_pred"
      ],
      "metadata": {
        "id": "Qj_CswUwSx9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the final evaluation, we also use sklearn and math\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, f1_score,matthews_corrcoef\n",
        "import math"
      ],
      "metadata": {
        "id": "Vy9sFnEWZ8aU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(predictions, sample_val, time_callback):\n",
        "  \"\"\"\n",
        "  Here, we do the final evaluation of the model. \n",
        "  We do that from the FAQ, then we invert the labels and finally, \n",
        "  we calculate the scorees from the Service perspective.\n",
        "\n",
        "  This method returns the full score series with all values we need \n",
        "  for the quantitative evaluation of the thesis. \n",
        "  \"\"\"\n",
        "\n",
        "  sample_val = evaluate_model(predictions, sample_val)\n",
        "  y_true, y_pred = get_y(sample_val)\n",
        "\n",
        "  cm_faq = confusion_matrix(y_true, y_pred)\n",
        "  scores = score(cm_faq, \"faq\", y_true, y_pred)\n",
        "\n",
        "  y_true, y_pred = invert_labels(y_true, y_pred)\n",
        "  cm_services = confusion_matrix(y_true, y_pred)\n",
        "  scores = scores.append(score(cm_services, \"services\", y_true, y_pred))\n",
        "\n",
        "  y_true, y_pred = invert_labels(y_true, y_pred)\n",
        "\n",
        "\n",
        "  scores = scores.append(pd.Series({\"time[sec]\":math.fsum(time_callback.times)}))\n",
        "\n",
        "  return scores"
      ],
      "metadata": {
        "id": "MIzkgwiAZ65u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_results_to_csv(hist, result_path=\"/content/drive/MyDrive/Masterarbeit/Colab_Data/results.csv\"):\n",
        "  \"\"\"\n",
        "  This method\n",
        "  (1) gets the result_csv\n",
        "  (2) appends a new row and \n",
        "  (3) writes the results back to the csv file \n",
        "  we can define in the result_path parameter. \n",
        "  \"\"\"\n",
        "  result_frame = pd.read_csv(result_path,index_col=False)\n",
        "  new_hist = {}\n",
        "  for key in hist.keys():\n",
        "    for idx,val in enumerate(hist[key]):\n",
        "      new_hist[f\"{key}_{idx}\"] = val\n",
        "  new_row = pd.Series(parameters).append(scores).append(pd.Series(new_hist))\n",
        "  result_frame = result_frame.append(new_row,ignore_index=True)\n",
        "  result_frame.to_csv(result_path, index=False)"
      ],
      "metadata": {
        "id": "UX-bpTgmbnjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Interpret"
      ],
      "metadata": {
        "id": "n5cJ8WFHdEjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# restart the runtime for it to work properly\n",
        "\n",
        "%pip install bertviz\n",
        "%pip install transformers-interpret"
      ],
      "metadata": {
        "id": "OaQ2R84u7JmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for the interpretation, we need torch and bertviz\n",
        "\n",
        "import torch\n",
        "from bertviz import head_view, model_view"
      ],
      "metadata": {
        "id": "1RbgEkSdeHoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# these two methods are some necessary adjustments to align our \n",
        "# tensorflow model to be able to adapt to the torch requirements of bertviz\n",
        "\n",
        "def show_head_view_tf(model, tokenizer, sentence_a, sentence_b=None):\n",
        "\n",
        "    if parameters[\"remove_special_chars\"]:\n",
        "      sentence_a = nospecial(sentence_a)\n",
        "      if sentence_b:\n",
        "        sentence_b = nospecial(sentence_b)\n",
        "\n",
        "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='tf', add_special_tokens=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    if sentence_b:\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "        sentence_b_start = token_type_ids[0].numpy().tolist().index(1)\n",
        "    else:\n",
        "        attention = model(input_ids)[-1]\n",
        "        sentence_b_start = None\n",
        "    \n",
        "    # Convert attention from TF tensors to torch tensors\n",
        "    attention = [torch.from_numpy(layer_attn.numpy()) for layer_attn in attention]\n",
        "    \n",
        "    input_id_list = input_ids[0].numpy().tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "    head_view(attention, tokens, sentence_b_start)\n",
        "\n",
        "def show_model_view_tf(model, tokenizer, sentence_a, sentence_b=None):\n",
        "\n",
        "    if parameters[\"remove_special_chars\"]:\n",
        "      sentence_a = nospecial(sentence_a)\n",
        "      if sentence_b:\n",
        "        sentence_b = nospecial(sentence_b)\n",
        "\n",
        "    inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='tf', add_special_tokens=True)\n",
        "    input_ids = inputs['input_ids']\n",
        "    if sentence_b:\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        attention = model(input_ids, token_type_ids=token_type_ids)[-1]\n",
        "        sentence_b_start = token_type_ids[0].numpy().tolist().index(1)\n",
        "    else:\n",
        "        attention = model(input_ids)[-1]\n",
        "        sentence_b_start = None\n",
        "    \n",
        "    # Convert attention from TF tensors to torch tensors\n",
        "    attention = [torch.from_numpy(layer_attn.numpy()) for layer_attn in attention]\n",
        "    \n",
        "    input_id_list = input_ids[0].numpy().tolist() # Batch index 0\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
        "    model_view(attention, tokens, sentence_b_start, display_mode=\"light\")"
      ],
      "metadata": {
        "id": "ahciG6GedLe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model_on_example_sentence(parameters:dict, example_sentence=\"Ich brauche einen neuen Personalausweis.\"):\n",
        "  \"\"\"\n",
        "  We load our previously saved model and show the Attention Heads and \n",
        "  Layers for an example sentence. \n",
        "  Per default, this sentence is set to\n",
        "  \"Ich brauche einen neuen Personalausweis.\"\n",
        "  \"\"\"\n",
        "\n",
        "  sentence_a = example_sentence\n",
        "\n",
        "  parameters[\"output_attentions\"] = True\n",
        "  parameters[\"num_hidden_layers\"] = 12\n",
        "  parameters[\"override\"] = False\n",
        "\n",
        "  model = load_model(parameters=parameters)\n",
        "\n",
        "  tokenizer = AutoTokenizer.from_pretrained(models[parameters[\"current_model\"]], \n",
        "                              output_attentions=parameters[\"output_attentions\"])\n",
        "  show_head_view_tf(model, tokenizer, sentence_a)\n",
        "  show_model_view_tf(model, tokenizer, sentence_a)"
      ],
      "metadata": {
        "id": "lENVYpJceDXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from transformers_interpret import SequenceClassificationExplainer\n",
        "\n",
        "\n",
        "def show_heads_for_many_real_examples(sample_val, parameters, how_many:int=10):\n",
        "  \"\"\"\n",
        "  This method iterates over as many real examples as you like and shows\n",
        "  the \"weights\" / importance of the words. \n",
        "  Will be used later in the Evaluation Part of the Script. \n",
        "  \"\"\"\n",
        "\n",
        "  # With both the model and tokenizer initialized we are now able to get explanations on an example text.\n",
        "\n",
        "  # tokenizer = BertTokenizer.from_pretrained(\"./my_model/\")\n",
        "  model = BertForSequenceClassification.from_pretrained(\"./my_model/\",from_tf=True)\n",
        "  \n",
        "  tokenizer = AutoTokenizer.from_pretrained(models[parameters[\"current_model\"]], \n",
        "                              output_attentions=parameters[\"output_attentions\"])\n",
        "  \n",
        "  cls_explainer = SequenceClassificationExplainer(model,tokenizer)\n",
        "\n",
        "  idx = 0\n",
        "\n",
        "  sample_val = sample_val.sample(frac=1,random_state=parameters[\"random_state\"])\n",
        "\n",
        "  for sample in sample_val.text.to_list()[:how_many]:\n",
        "    word_attributions = cls_explainer(sample)\n",
        "    print(word_attributions)\n",
        "    cls_explainer.visualize(true_class=sample_val.label.to_list()[idx])\n",
        "    idx+=1"
      ],
      "metadata": {
        "id": "ts4ESE4lBmda"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_correlation(sample_val):\n",
        "  \"\"\"\n",
        "  Returns the specific correlation between the text length and the performance\n",
        "  or accuracy of the model. \n",
        "  \"\"\"\n",
        "\n",
        "  correlation = sample_val[\"text_length\"].astype(float).corr(sample_val[\"same\"].astype(float))\n",
        "  \n",
        "  return round(correlation,4)"
      ],
      "metadata": {
        "id": "VhgQKLUuBmq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize the Classifier\n",
        "\n",
        "Then, we prepare the data and load the model. "
      ],
      "metadata": {
        "id": "aapHIqmG5S0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the Data"
      ],
      "metadata": {
        "id": "uTbrLhWz0p6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the data\n",
        "mount_drive()\n",
        "df_services, df_faq = load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgdfXynUg23e",
        "outputId": "d0b40ab8-f10a-47b2-c337-2edc8091bcf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the parameters\n",
        "parameters = get_parameters(possibilities=get_possibilities())"
      ],
      "metadata": {
        "id": "kZLO29KoZNCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the train data\n",
        "df = generate_data(parameters=parameters)"
      ],
      "metadata": {
        "id": "ymrbzVymyeRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show some info\n",
        "print(\"The data is as follows:\")\n",
        "print(df, \"\\n\\n\")\n",
        "print(\"The label distribution is as follows:\")\n",
        "print(df[\"label\"].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3gQ8cgcCunZ",
        "outputId": "3786f852-16f5-4ff5-ccce-1146a1122de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The data is as follows:\n",
            "                                                  text  label\n",
            "661  Jugendschutz Erzieherischer Kinder und Jugends...      0\n",
            "216  Wo kann ich aktuell einen Antrag auf Ersatzfüh...      1\n",
            "188  Kartenverkauf Landeskartenwerke Sonderkarten B...      0\n",
            "172           Wie soll ich die Projektlaufzeit planen       1\n",
            "320            Aufenthaltstitel für ehemalige Deutsche      0\n",
            "..                                                 ...    ...\n",
            "802  Glücksspiel Buchmachergehilfenerlaubnis beantr...      0\n",
            "53               Fahrerlaubnis Neuerteilung beantragen      0\n",
            "350  Sozialversicherung Auskunft Kontenklärung für ...      0\n",
            "79   Handwerk Eintragung in das Verzeichnis handwer...      0\n",
            "792  Feuerwerk Verkauf von Kleinfeuerwerk und Klein...      0\n",
            "\n",
            "[1138 rows x 2 columns] \n",
            "\n",
            "\n",
            "The label distribution is as follows:\n",
            "0    881\n",
            "1    257\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHkhxl4cJYr7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "e16a7fc6e7ba458da91e016e38b96624",
            "bfcd55c246324a688dd55dcc20e19afe",
            "1f7a00e992054c95ab678f6e7a149727",
            "18dc0cdf9c7c4a9eab322767f6354f42",
            "c3d2601661cf4f8cbfdd049c2c8588d1",
            "1c73284bc06a41d7a48b938cccc754d1",
            "9e392f9eb0164e1f90ac8634bf38267f",
            "be26b8c6996b4a52bd737cc72587b537",
            "b9f6d91ee3c6457b96c87eb5b2e51698",
            "29d2866d747c43b5a202c8fbc80755f4",
            "d4590bdf92c94b139b00f31bb2a7e31a",
            "9e744d6085aa4e7ca1b03c285d96f0dd",
            "12c80381fae8430aae60016365fe3375",
            "a9cefc02dacc4b388bc4d7a0012f380c",
            "9479790bcd9349fcaea9b2af2e8de83f",
            "64cc0a916286480fb0834d159ec61f95",
            "3ceba265950d4e09a54ae4a1dbf5a310",
            "e26b362dc77a488ead63acbd5bd334c2",
            "ae3b535d441543ceaabcfa4ff9617943",
            "510b7e5dd221458c80849d678446a557",
            "6992a243d30946f389092c7a4cb4f4e9",
            "c7ce37369ab944ab82bacb696f4d1b99"
          ]
        },
        "outputId": "a2457375-c9dc-4e2f-c950-ea1274969ba5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e16a7fc6e7ba458da91e016e38b96624"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e744d6085aa4e7ca1b03c285d96f0dd"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# now, we turn the df into tensors\n",
        "\n",
        "tf_train_dataset, tf_test_dataset = tensor_df(df, parameters=parameters)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the Model"
      ],
      "metadata": {
        "id": "deC2xM9Y0t4n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdedc0S4ISgN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aeaa17f-a6e8-4895-a32a-d8a9f3e924a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at ./my_model/ were not used when initializing TFBertForSequenceClassification: ['dropout_37']\n",
            "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at ./my_model/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "# get the Model accoarding to the Parameter Settings\n",
        "\n",
        "model = load_model(parameters=parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpcgidEDHRyV"
      },
      "outputs": [],
      "source": [
        "# Compile the Model\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizers[parameters[\"optimizer\"]],\n",
        "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Model\n",
        "\n",
        "We train the model. "
      ],
      "metadata": {
        "id": "coAVkvw02iBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model and save its, its training history and the time(s)\n",
        "\n",
        "model, hist, time_callback = train_model(model=model, parameters=parameters, tf_train_dataset=tf_train_dataset, tf_test_dataset=tf_test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKpBXtIq2u7R",
        "outputId": "79d47d62-d267-46cb-ed6f-d276650f0cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/8\n",
            "128/128 [==============================] - 148s 1s/step - loss: 2.6109e-05 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4141 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 2/8\n",
            "128/128 [==============================] - 126s 986ms/step - loss: 3.2277e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4344 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 3/8\n",
            "128/128 [==============================] - 126s 988ms/step - loss: 2.1716e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4462 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 4/8\n",
            "128/128 [==============================] - 126s 987ms/step - loss: 1.6915e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4547 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 5/8\n",
            "128/128 [==============================] - 126s 985ms/step - loss: 1.3901e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4613 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 6/8\n",
            "128/128 [==============================] - 126s 984ms/step - loss: 1.1805e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4665 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 7/8\n",
            "128/128 [==============================] - 126s 985ms/step - loss: 1.0506e-06 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4709 - val_sparse_categorical_accuracy: 0.9649\n",
            "Epoch 8/8\n",
            "128/128 [==============================] - 126s 985ms/step - loss: 9.4157e-07 - sparse_categorical_accuracy: 1.0000 - val_loss: 0.4747 - val_sparse_categorical_accuracy: 0.9649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model\n",
        "Do all evaluations."
      ],
      "metadata": {
        "id": "4DhFDDCz3sRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the evaluation / validation / test dataset\n",
        "\n",
        "sample_val = get_test_data(parameters=parameters)\n",
        "\n",
        "# and then turn it into tensors\n",
        "\n",
        "tf_val_test = tensor_df(sample_val, parameters=parameters, val=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "efe1bae606364d148f158b5512272d84",
            "613303c267654f449532e3151a492dd1",
            "177efe5e1f744419a59cac6c3d41fcdd",
            "8b016fd91d704adaaa1ade402417db3e",
            "7e9c3f5db1964b67b32e93cca9ed288e",
            "57453d656bc349c5b9222b65c708ed48",
            "cec9c1282e6240c6a959d9cc812ace0e",
            "b852dadee78d4dcb9c7cb2f7144570f4",
            "854c6493716b4ea6aa6e80b9f53dacfe",
            "070ea94e9f4c4cc6b25f0852c5a6ce46",
            "87340113ee37469b9e1c913cc595a2a8"
          ]
        },
        "id": "c6e2y5c77tua",
        "outputId": "969147d8-1741-4b7e-c349-c6f4223d05ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?ba/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe1bae606364d148f158b5512272d84"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jx8aKaGwLBrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b33914a8-3d89-42bf-a445-c51f5ac5e8cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 87s 335ms/step\n"
          ]
        }
      ],
      "source": [
        "# to make predictions\n",
        "\n",
        "predictions = model.predict(tf_val_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# and now, we get all scores\n",
        "\n",
        "scores = eval_model(predictions=predictions, sample_val=sample_val, time_callback=time_callback)"
      ],
      "metadata": {
        "id": "3JqkMQedJ3Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENsSaT5VWLpO"
      },
      "outputs": [],
      "source": [
        "write_results_to_csv(hist)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Interpret the Model\n",
        "And finally interpret the results. "
      ],
      "metadata": {
        "id": "Pg1l4IGfcjOx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHZI05MChf0d"
      },
      "outputs": [],
      "source": [
        "if parameters[\"explainable\"]:\n",
        "\n",
        "  # visualize an example sentence\n",
        "  visualize_model_on_example_sentence(parameters=parameters)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if parameters[\"explainable\"]:\n",
        "\n",
        "  # show real examples\n",
        "  show_heads_for_many_real_examples(sample_val,parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FYOOyUBqGoNK",
        "outputId": "74db9f96-55bc-4bf4-d8fc-08f41fdc4118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('Um', -0.20596806129412581), ('##melde', 0.7289676552613763), ('##n', 0.33480172249281304), ('nach', 0.3097405202487212), ('umzu', 0.056972134532900884), ('##g', 0.46357966729369454), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.69</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Um                    </font></mark><mark style=\"background-color: hsl(120, 75%, 64%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##melde                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##n                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nach                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> umzu                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##g                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('Ich', 0.32505710854648273), ('bin', 0.24693045068081243), ('Reise', 0.006131195031992667), ('##rück', 0.057567252326286844), ('##kehr', 0.03020300877907522), ('##er', 0.11844569940244655), ('aus', 0.13001866914098742), ('einem', 0.08971251205046502), ('Risiko', 0.008756776682311618), ('##gebiet', -0.0597804387837352), ('Welche', 0.7435317931274418), ('##n', 0.03763353430872337), ('Text', 0.03456028950594967), ('benöt', 0.04913714804860758), ('##ige', 0.023163943591796805), ('ich', 0.43515312523237604), ('zum', 0.059877354168393536), ('Frei', 0.029180214913119805), ('##testen', -0.031192203360573583), ('PC', 0.04969083318095675), ('##R', 0.023652760798993887), ('oder', 0.08509036136984209), ('reicht', 0.039093500657054865), ('ein', 0.13885620680524957), ('Schnell', 0.005489780170894013), ('##test', 0.0467841302573735), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.72</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 84%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Ich                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bin                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Reise                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##rück                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##kehr                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##er                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> aus                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> einem                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Risiko                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##gebiet                    </font></mark><mark style=\"background-color: hsl(120, 75%, 63%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Welche                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##n                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Text                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> benöt                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ige                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ich                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> zum                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Frei                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##testen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> PC                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##R                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> oder                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> reicht                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ein                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Schnell                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##test                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('brauche', -0.0035058332594901436), ('ich', 0.8869762565605234), ('einen', 0.13894182910800695), ('Termin', 0.043395767675220846), ('für', 0.18443942154113968), ('ein', 0.29268340951389143), ('erweiterte', 0.14170572516100718), ('##s', 0.17489259050609826), ('Führungs', -0.01769516641132262), ('##zeug', 0.05836681693642998), ('##nis', 0.13417746267154845), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.03</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> brauche                    </font></mark><mark style=\"background-color: hsl(120, 75%, 56%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ich                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> einen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Termin                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> für                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ein                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> erweiterte                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##s                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Führungs                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##zeug                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##nis                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('Melde', 0.8355074561782707), ('##register', -0.09328034247698269), ('##aus', 0.25561196444564527), ('##kunft', 0.4773767820182817), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.48</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 59%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Melde                    </font></mark><mark style=\"background-color: hsl(0, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##register                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##aus                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##kunft                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('Gib', 0.18014286492289824), ('##t', 0.16368987396398002), ('es', 0.5745664082158662), ('eine', 0.2008409957956396), ('trage', -0.0337043700403531), ('##verpflichtung', -0.02081628568668618), ('für', 0.21364190663533486), ('Mas', 0.012740509436692036), ('##ken', 0.018347343395351094), ('auf', 0.17783919262060457), ('öffentlichen', 0.05269812670553654), ('Straßen', -0.0095097744800326), ('und', 0.1316693538333293), ('wenn', 0.19880198167727126), ('ja', 0.13284701738806423), ('welche', 0.6431000813858728), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.64</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Gib                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##t                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> es                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> eine                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> trage                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##verpflichtung                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> für                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Mas                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ken                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> auf                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> öffentlichen                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Straßen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> und                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wenn                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ja                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> welche                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('Dar', 0.3955166338182706), ('##f', 0.5166313468866274), ('ich', 0.4791194346043311), ('derzeit', 0.16647324965304944), ('meinen', 0.4267155536702288), ('Sohn', 0.09763151409710155), ('in', 0.35146240206550017), ('Rostock', -0.06113781441859121), ('besuchen', 0.02254195233419652), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.39</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 81%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Dar                    </font></mark><mark style=\"background-color: hsl(120, 75%, 75%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##f                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ich                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> derzeit                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> meinen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Sohn                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Rostock                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> besuchen                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('ich', 0.5688709759641511), ('brä', 0.31305380211457906), ('##uchte', 0.019168420696645632), ('unbedingt', 0.17871359841048567), ('einen', 0.5789637601056098), ('ter', -0.034919207234508746), ('##min', -0.004332980802455864), ('bei', 0.352193942933482), ('einem', 0.2884311552912477), ('Bürger', 0.045801544440011686), ('##amt', -0.017581341002843035), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>1</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.29</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ich                    </font></mark><mark style=\"background-color: hsl(120, 75%, 85%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> brä                    </font></mark><mark style=\"background-color: hsl(120, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##uchte                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> unbedingt                    </font></mark><mark style=\"background-color: hsl(120, 75%, 72%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> einen                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ter                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##min                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bei                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> einem                    </font></mark><mark style=\"background-color: hsl(120, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Bürger                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##amt                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('es', 0.08567029481450668), ('gibt', 0.43927562618018334), ('keinen', 0.09567582262581696), ('ter', 0.03829483943007786), ('##min', 0.02348931776961513), ('innerhalb', 0.07248270125397847), ('der', 0.2575868307545052), ('nächsten', 0.20893134856087495), ('zwei', 0.21698154128516914), ('wo', 0.11613937486840643), ('##chen', 0.15057491665948108), ('zur', 0.47441989064938067), ('anmel', -0.16943107365069132), ('##dung', -0.04471257607822439), ('in', 0.27827652571679545), ('ber', -0.021528620226342603), ('##lin', 0.09036999682172267), ('ist', 0.34468268434579963), ('das', 0.185945672025263), ('ein', 0.286662699699384), ('problem', 0.1123406268237385), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>3.24</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> es                    </font></mark><mark style=\"background-color: hsl(120, 75%, 79%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> gibt                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> keinen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ter                    </font></mark><mark style=\"background-color: hsl(120, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##min                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> innerhalb                    </font></mark><mark style=\"background-color: hsl(120, 75%, 88%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> der                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> nächsten                    </font></mark><mark style=\"background-color: hsl(120, 75%, 90%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> zwei                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wo                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##chen                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> zur                    </font></mark><mark style=\"background-color: hsl(0, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> anmel                    </font></mark><mark style=\"background-color: hsl(0, 75%, 99%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##dung                    </font></mark><mark style=\"background-color: hsl(120, 75%, 87%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> in                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ber                    </font></mark><mark style=\"background-color: hsl(120, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##lin                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ist                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> das                    </font></mark><mark style=\"background-color: hsl(120, 75%, 86%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ein                    </font></mark><mark style=\"background-color: hsl(120, 75%, 95%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> problem                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('Grunds', 0.49298855209648224), ('##teuer', 0.8700357966783975), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_0</b></text></td><td><text style=\"padding-right:2em\"><b>1.36</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 76%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> Grunds                    </font></mark><mark style=\"background-color: hsl(120, 75%, 57%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##teuer                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('[CLS]', 0.0), ('muss', 0.4664261034688644), ('der', 0.6599455605579276), ('ehe', -0.11871079563074319), ('##partner', 0.061402304251567175), ('bei', 0.1620957364053492), ('der', 0.35740666018698947), ('anmel', -0.1147165653161756), ('##dung', -0.07487205038868691), ('bei', 0.15516689198144404), ('der', 0.2356132572413218), ('wohn', -0.06403441468801677), ('##ung', 0.14882269325716904), ('mit', 0.18140479428456216), ('##kommen', 0.1323975728805735), ('[SEP]', 0.0)]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table width: 100%><div style=\"border-top: 1px solid; margin-top: 5px;             padding-top: 5px; display: inline-block\"><b>Legend: </b><span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 60%)\"></span> Negative  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(0, 75%, 100%)\"></span> Neutral  <span style=\"display: inline-block; width: 10px; height: 10px;                 border: 1px solid; background-color:                 hsl(120, 75%, 50%)\"></span> Positive  </div><tr><th>True Label</th><th>Predicted Label</th><th>Attribution Label</th><th>Attribution Score</th><th>Word Importance</th><tr><td><text style=\"padding-right:2em\"><b>0</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1 (1.00)</b></text></td><td><text style=\"padding-right:2em\"><b>LABEL_1</b></text></td><td><text style=\"padding-right:2em\"><b>2.19</b></text></td><td><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [CLS]                    </font></mark><mark style=\"background-color: hsl(120, 75%, 77%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> muss                    </font></mark><mark style=\"background-color: hsl(120, 75%, 68%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> der                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ehe                    </font></mark><mark style=\"background-color: hsl(120, 75%, 97%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##partner                    </font></mark><mark style=\"background-color: hsl(120, 75%, 92%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bei                    </font></mark><mark style=\"background-color: hsl(120, 75%, 83%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> der                    </font></mark><mark style=\"background-color: hsl(0, 75%, 96%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> anmel                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##dung                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> bei                    </font></mark><mark style=\"background-color: hsl(120, 75%, 89%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> der                    </font></mark><mark style=\"background-color: hsl(0, 75%, 98%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> wohn                    </font></mark><mark style=\"background-color: hsl(120, 75%, 93%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##ung                    </font></mark><mark style=\"background-color: hsl(120, 75%, 91%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> mit                    </font></mark><mark style=\"background-color: hsl(120, 75%, 94%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> ##kommen                    </font></mark><mark style=\"background-color: hsl(0, 75%, 100%); opacity:1.0;                     line-height:1.75\"><font color=\"black\"> [SEP]                    </font></mark></td><tr></table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if parameters[\"explainable\"]:\n",
        "\n",
        "  # show correlation betweeen text length and performance\n",
        "  correlation = get_correlation(sample_val)\n",
        "  print(f\"The Correlation between the 'Correctness' of the BC and the length of the user query is {correlation}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1M5Nu3wGqCC",
        "outputId": "aff2f77e-0e67-4a79-c153-56a8527976eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The correlation between the correctness of the SCC and the length of the user query is -0.0309\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SNI178QgzWph",
        "5WGF4kTnKl7p",
        "u491BbWoKr64",
        "FDNSNh9MUY05",
        "z2xOMutJUfjF",
        "45CYA-x4Sc6h",
        "n5cJ8WFHdEjT",
        "aapHIqmG5S0k",
        "coAVkvw02iBg"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOhr9b8TNYzKDbyUVQX56dL",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e16a7fc6e7ba458da91e016e38b96624": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bfcd55c246324a688dd55dcc20e19afe",
              "IPY_MODEL_1f7a00e992054c95ab678f6e7a149727",
              "IPY_MODEL_18dc0cdf9c7c4a9eab322767f6354f42"
            ],
            "layout": "IPY_MODEL_c3d2601661cf4f8cbfdd049c2c8588d1"
          }
        },
        "bfcd55c246324a688dd55dcc20e19afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c73284bc06a41d7a48b938cccc754d1",
            "placeholder": "​",
            "style": "IPY_MODEL_9e392f9eb0164e1f90ac8634bf38267f",
            "value": " 50%"
          }
        },
        "1f7a00e992054c95ab678f6e7a149727": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be26b8c6996b4a52bd737cc72587b537",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9f6d91ee3c6457b96c87eb5b2e51698",
            "value": 1
          }
        },
        "18dc0cdf9c7c4a9eab322767f6354f42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29d2866d747c43b5a202c8fbc80755f4",
            "placeholder": "​",
            "style": "IPY_MODEL_d4590bdf92c94b139b00f31bb2a7e31a",
            "value": " 1/2 [00:00&lt;00:00,  4.05ba/s]"
          }
        },
        "c3d2601661cf4f8cbfdd049c2c8588d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c73284bc06a41d7a48b938cccc754d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e392f9eb0164e1f90ac8634bf38267f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be26b8c6996b4a52bd737cc72587b537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9f6d91ee3c6457b96c87eb5b2e51698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29d2866d747c43b5a202c8fbc80755f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4590bdf92c94b139b00f31bb2a7e31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e744d6085aa4e7ca1b03c285d96f0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_12c80381fae8430aae60016365fe3375",
              "IPY_MODEL_a9cefc02dacc4b388bc4d7a0012f380c",
              "IPY_MODEL_9479790bcd9349fcaea9b2af2e8de83f"
            ],
            "layout": "IPY_MODEL_64cc0a916286480fb0834d159ec61f95"
          }
        },
        "12c80381fae8430aae60016365fe3375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ceba265950d4e09a54ae4a1dbf5a310",
            "placeholder": "​",
            "style": "IPY_MODEL_e26b362dc77a488ead63acbd5bd334c2",
            "value": "  0%"
          }
        },
        "a9cefc02dacc4b388bc4d7a0012f380c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae3b535d441543ceaabcfa4ff9617943",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_510b7e5dd221458c80849d678446a557",
            "value": 0
          }
        },
        "9479790bcd9349fcaea9b2af2e8de83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6992a243d30946f389092c7a4cb4f4e9",
            "placeholder": "​",
            "style": "IPY_MODEL_c7ce37369ab944ab82bacb696f4d1b99",
            "value": " 0/1 [00:00&lt;?, ?ba/s]"
          }
        },
        "64cc0a916286480fb0834d159ec61f95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ceba265950d4e09a54ae4a1dbf5a310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26b362dc77a488ead63acbd5bd334c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae3b535d441543ceaabcfa4ff9617943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "510b7e5dd221458c80849d678446a557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6992a243d30946f389092c7a4cb4f4e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7ce37369ab944ab82bacb696f4d1b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efe1bae606364d148f158b5512272d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_613303c267654f449532e3151a492dd1",
              "IPY_MODEL_177efe5e1f744419a59cac6c3d41fcdd",
              "IPY_MODEL_8b016fd91d704adaaa1ade402417db3e"
            ],
            "layout": "IPY_MODEL_7e9c3f5db1964b67b32e93cca9ed288e"
          }
        },
        "613303c267654f449532e3151a492dd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57453d656bc349c5b9222b65c708ed48",
            "placeholder": "​",
            "style": "IPY_MODEL_cec9c1282e6240c6a959d9cc812ace0e",
            "value": " 50%"
          }
        },
        "177efe5e1f744419a59cac6c3d41fcdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b852dadee78d4dcb9c7cb2f7144570f4",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_854c6493716b4ea6aa6e80b9f53dacfe",
            "value": 1
          }
        },
        "8b016fd91d704adaaa1ade402417db3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_070ea94e9f4c4cc6b25f0852c5a6ce46",
            "placeholder": "​",
            "style": "IPY_MODEL_87340113ee37469b9e1c913cc595a2a8",
            "value": " 1/2 [00:00&lt;00:00,  4.17ba/s]"
          }
        },
        "7e9c3f5db1964b67b32e93cca9ed288e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57453d656bc349c5b9222b65c708ed48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec9c1282e6240c6a959d9cc812ace0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b852dadee78d4dcb9c7cb2f7144570f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "854c6493716b4ea6aa6e80b9f53dacfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "070ea94e9f4c4cc6b25f0852c5a6ce46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87340113ee37469b9e1c913cc595a2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}